name: Run daily update
on:
  schedule:
    - cron: "08 23 * * *"

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout
      uses: actions/checkout@v2
   
    - name: Set up Python 3.x
      uses: actions/setup-python@v1
      with:
        python-version: '3.x'

    - name: Upgrade pip
      run: |
        python -m pip install --upgrade pip
        
    - name: Install libgdal-dev and gdal
      run: |
        sudo apt-get install libgdal-dev
        export CPLUS_INCLUDE_PATH=/usr/include/gdal
        export C_INCLUDE_PATH=/usr/include/gdal
        
    - name: Install fiona and wheel
      run: |
        pip install Fiona
        pip install wheel

    - name: Install python dependencies
      run: |
        pip install -r requirements.txt
        
    - name: Install R 
      run: |
        sudo apt install r-base
        
    - name: Install Chromium
      run: |
        sudo apt-get clean 
        sudo apt-get update
        sudo apt-get install chromium-browser

    - name: Clone data from yesterday
      run: |
        git clone https://${GITHUB_ACTOR}:${{ secrets.GITHUB_TOKEN }}@github.com/MJHutchinson/US-covid19-data-scraping --single-branch -b update_data output 
        git config --global user.name "GitHub Actions"
        git config --global user.email action@github.com

    - name: Update Data Sources
      run: |
        make files
        today=$(date +'%Y-%m-%d')
        cp -a data/. output/data/
        cp -a html/. output/html/
        cp -a csvs/. output/csvs/
        cp -a pngs/. output/pngs/

        cd output
        git add -f .
        git status
        git commit -m "Automated data update"
        git push \
          "https://${GITHUB_ACTOR}:${{ secrets.GITHUB_TOKEN }}@github.com/MJHutchinson/US-covid19-data-scraping" \
          HEAD:update_data
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY}}
        AWS_BUCKET: ${{ secrets.AWS_BUCKET }}
